{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/anna.txt','r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Convert characters to intergers and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = tuple(set(text))\n",
    "\n",
    "int2char = dict(enumerate(chars))\n",
    "\n",
    "char2int = {ch:ii for ii,ch in int2char.items()}\n",
    "\n",
    "encoded = np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 : C\n",
      "28 : h\n",
      "25 : a\n",
      "32 : p\n",
      "22 : t\n",
      "69 : e\n",
      "49 : r\n",
      "63 :  \n",
      "74 : 1\n",
      "12 : \n",
      "\n",
      "12 : \n",
      "\n",
      "12 : \n",
      "\n",
      "21 : H\n",
      "25 : a\n",
      "32 : p\n",
      "32 : p\n",
      "29 : y\n",
      "63 :  \n",
      "56 : f\n",
      "25 : a\n",
      "30 : m\n",
      "17 : i\n",
      "55 : l\n",
      "17 : i\n",
      "69 : e\n",
      "8 : s\n",
      "63 :  \n",
      "25 : a\n",
      "49 : r\n",
      "69 : e\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print('{} : {}'.format(encoded[i],int2char[encoded[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(arr,n_labels):\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    \n",
    "    one_hot[np.arange(one_hot.shape[0]),arr.flatten()] = 1\n",
    "    \n",
    "    one_hot = one_hot.reshape((*arr.shape,n_labels))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the function\n",
    "\n",
    "one_hot_val = one_hot_encode(np.array([[1,2,3]]),8)\n",
    "\n",
    "one_hot_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making training mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr,batch_size,seq_length):\n",
    "    batch_ele_count = batch_size * seq_length\n",
    "    \n",
    "    batches = len(arr) // batch_ele_count\n",
    "    \n",
    "    arr = arr[:(batches*batch_ele_count)]\n",
    "    \n",
    "    arr = arr.reshape(batch_size,-1)\n",
    "    \n",
    "    for n in range(0,arr.shape[1],seq_length):\n",
    "        x = arr[:,n:n+seq_length]\n",
    "        y = np.zeros_like(x)\n",
    "        \n",
    "        try:\n",
    "            y[:,:-1] , y[:,-1] = x[:,1:] , x[:,n+seq_length]\n",
    "        except IndexError:\n",
    "            y[:,:-1] , y[:,-1] = x[:,1:] , x[:,0]\n",
    "            \n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = get_batches(np.array([1,2,3,4,5,6,7,8,9,10]),2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , y = next(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[1 2 3]\n",
      " [4 5 6]] \n",
      "\n",
      " y: [[2 3 1]\n",
      " [5 6 4]]\n"
     ]
    }
   ],
   "source": [
    "print('x: {} \\n\\n y: {}'.format(x[:10,:10] , y[:10,:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU Available\n"
     ]
    }
   ],
   "source": [
    "if(torch.cuda.is_available()):\n",
    "    print(\"GPU is present\")\n",
    "    gpu = True\n",
    "else:\n",
    "    print(\"No GPU Available\")\n",
    "    gpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-15-b2b315cc3409>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-b2b315cc3409>\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,tokens,n_hidden=256,n_layers=2,drop_prob=0.5,lr=0.001):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch:ii for ii in self.int2char.items()}\n",
    "        \n",
    "        self.lstm = nn.LSTM(len(self.chars),n_hidden,n_layers,dropout=drop_prob,batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(n_hidden,len(self.chars))\n",
    "        \n",
    "    def forward(self,x,hidden):\n",
    "        \n",
    "        r_output , hidden = self.lstm(x,hidden)\n",
    "        \n",
    "        out = self.dropout(r_output)\n",
    "        \n",
    "        out = out.view(-1,self.n_hidden)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out,hidden\n",
    "        \n",
    "    def init_hidden(self,batch_size):\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if(gpu):\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
